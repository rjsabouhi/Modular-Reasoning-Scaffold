{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Modular Reasoning Scaffold (MRS)","text":"<p>A lightweight, model-agnostic meta-reasoning layer that gives small language models the ability to perform stable, multi-step recursive reasoning.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Structured recursion nodes  </li> <li>Drift monitoring and stabilization  </li> <li>State slots (persistent intermediate memory)  </li> <li>Constraint layers  </li> <li>Topology engine for flow, branching, and halting  </li> <li>Fully transparent + interpretable reasoning chain</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>README: Overview, installation, and usage  </li> <li>MRS v1.0 PDF: Full formal specification and math core  </li> <li>API docs coming soon</li> </ul>"},{"location":"#links","title":"Links","text":"<ul> <li>GitHub Repo: https://github.com/rjsabouhi/Modular-Reasoning-Scaffold  </li> <li>PyPI Package: https://pypi.org/project/mrs-scaffold/  </li> <li>Contact: symbolicsuite@gmail.com</li> </ul>"},{"location":"architecture/","title":"Architecture","text":"<p>The Modular Reasoning Scaffold (MRS) provides a stable, multi-step recursive reasoning framework for small and mid-sized language models. The core architecture has five major components:</p>"},{"location":"architecture/#1-recursion-nodes","title":"1. Recursion Nodes","text":"<p>Each reasoning step runs inside a \u201cnode\u201d that carries: - local state - the current prompt context - constraint settings - slot references</p> <p>Nodes chain together into a stable reasoning graph.</p>"},{"location":"architecture/#2-state-slots-persistent-memory","title":"2. State Slots (Persistent Memory)","text":"<p>Slots are small, persistent containers that survive across recursion steps.</p> <p>They allow: - intermediate result storage - condition propagation - branch comparison - recursive loop awareness  </p>"},{"location":"architecture/#3-constraint-layers","title":"3. Constraint Layers","text":"<p>Constraints define: - what a step is allowed to output - what formats are legal - what conditions must remain true  </p> <p>They prevent drift, hallucination, and runaway recursion.</p>"},{"location":"architecture/#4-flow-engine-topology","title":"4. Flow Engine (Topology)","text":"<p>Determines: - step \u2192 step transitions - branching - merging - halting conditions  </p> <p>Equivalent to a lightweight computational graph optimized for reasoning.</p>"},{"location":"architecture/#5-drift-monitor","title":"5. Drift Monitor","text":"<p>Tracks: - semantic deviation - logical inconsistency - recursion instability  </p> <p>If drift exceeds the threshold \u2192 halting or correction is triggered.</p>"},{"location":"architecture/#summary-diagram-high-level","title":"Summary Diagram (High-Level)","text":"<p>```mermaid flowchart TD     A[Input] --&gt; B[Recursion Node]     B --&gt; C[State Slots]     C --&gt; D[Constraint Layer]     D --&gt; E[Flow Engine]     E --&gt; F[Next Node]ooo</p>"},{"location":"examples/","title":"Examples","text":"<p>This page shows how to use the Modular Reasoning Scaffold (MRS) in realistic scenarios. Each example illustrates core operators and how the engine manages structure, state, and stability.</p>"},{"location":"examples/#1-basic-reasoning-example","title":"1. Basic Reasoning Example","text":"<p>Simple use of <code>INFER</code> + <code>UPDATE</code> to produce a multi-step chain.</p>"},{"location":"examples/#input","title":"Input","text":"<pre><code>What is the average of 12 and 20?\n</code></pre>"},{"location":"examples/#mrs-reasoning-conceptual","title":"MRS Reasoning (conceptual)","text":"<pre><code>STEP 1:\nINFER \u2192 Identify task.\n\"Compute the average of two numbers.\"\n\nSTEP 2:\nINFER \u2192 Extract numbers.\n12 and 20\n\nSTEP 3:\nUPDATE(slot=\"sum\", value=32)\n\nSTEP 4:\nUPDATE(slot=\"average\", value=16)\n\nSTEP 5:\nHALT\nEMIT(16)\n</code></pre>"},{"location":"examples/#output","title":"Output","text":"<pre><code>16\n</code></pre>"},{"location":"examples/#2-branching-example","title":"2. Branching Example","text":"<p>Demonstrates <code>BRANCH</code> + <code>SELECT</code>.</p>"},{"location":"examples/#input_1","title":"Input","text":"<pre><code>Summarize this in one sentence:\n\"The cat sat on the mat because it was warm.\"\n</code></pre>"},{"location":"examples/#mrs-reasoning","title":"MRS Reasoning","text":"<pre><code>STEP 1:\nBRANCH(\n  path1 = \"Cat sat on mat to stay warm.\",\n  path2 = \"Warmth caused the cat to sit on the mat.\",\n  path3 = \"Cat found warm mat and sat on it.\"\n)\n\nSTEP 2:\nSELECT(best semantic compression)\n\n\u2192 returns path1\n</code></pre>"},{"location":"examples/#output_1","title":"Output","text":"<pre><code>\"The cat sat on the mat to stay warm.\"\n</code></pre>"},{"location":"examples/#3-constraint-repair-loop-example","title":"3. Constraint + Repair Loop Example","text":"<p>Demonstrates <code>CHECK</code> + <code>REPAIR</code>.</p>"},{"location":"examples/#input_2","title":"Input","text":"<pre><code>Return a JSON object with fields:\n\"name\", \"age\", \"city\"\n</code></pre>"},{"location":"examples/#mrs-reasoning_1","title":"MRS Reasoning","text":"<pre><code>STEP 1:\nINFER \u2192 attempt to create JSON\n{\"name\": \"Bob\", \"city\": \"LA\"}     \u2717 missing \"age\"\n\nSTEP 2:\nCHECK(JSON schema)\n\u2192 fail\n\nSTEP 3:\nREPAIR \u2192 regenerate object\n{\"name\": \"Bob\", \"age\": 32, \"city\": \"LA\"}   \u2713\n\nSTEP 4:\nHALT\nEMIT\n</code></pre>"},{"location":"examples/#output_2","title":"Output","text":"<pre><code>{\"name\": \"Bob\", \"age\": 32, \"city\": \"LA\"}\n</code></pre>"},{"location":"examples/#notes","title":"Notes","text":"<ul> <li>These examples are conceptual: MRS does not force a specific syntax.  </li> <li>They show the internal structure of how reasoning unfolds.  </li> <li>Real implementations will embed this logic inside prompt templates, evaluators, or agent frameworks.</li> </ul>"},{"location":"interface/","title":"Interface","text":"<p>The MRS interface defines how a language model interacts with recursion nodes, slots, constraints, and the flow engine. It is intentionally minimal, so even small models can use it without overhead.</p>"},{"location":"interface/#core-interface-objects","title":"Core Interface Objects","text":""},{"location":"interface/#1-nodecontext","title":"1. <code>NodeContext</code>","text":"<p>Holds all information a single reasoning step needs.</p> <p>Fields: - <code>content</code>: current text or instruction - <code>slots</code>: dictionary of state slot values - <code>step</code>: current step index - <code>constraints</code>: active constraint set - <code>metadata</code>: free-form metadata for advanced use</p>"},{"location":"interface/#2-stateslot","title":"2. <code>StateSlot</code>","text":"<p>A small persistent memory cell.</p> <p>Properties: - <code>name</code> - <code>value</code> - <code>locked</code> (prevents accidental overwrite) - <code>history</code> (optional tracking of past values)</p>"},{"location":"interface/#3-constraintset","title":"3. <code>ConstraintSet</code>","text":"<p>Defines structural and semantic rules.</p> <p>Examples: - output must be JSON - output must contain \u201creasoning\u201d and \u201canswer\u201d sections - recursion depth \u2264 N - forbid speculation - enforce monotonic reasoning  </p>"},{"location":"interface/#4-flowcontroller","title":"4. <code>FlowController</code>","text":"<p>Determines step transitions.</p> <p>Responsibilities: - <code>next_step()</code> - <code>halt()</code> - <code>branch()</code> - <code>merge()</code></p>"},{"location":"interface/#execution-loop","title":"Execution Loop","text":"<p>The full reasoning cycle for one task:</p> <p>```python while not controller.halted:     node = create_node(context)     output = model(node)     context = update_context(node, output)     controller.next_step(context)</p>"},{"location":"math-core/","title":"Math Core","text":"<p>The mathematical core of MRS defines the formal structure behind stable, multi-step recursive reasoning. It turns a language model (LM) into a state machine with constraint-guided transitions.</p>"},{"location":"math-core/#1-recursion-node-formal-definition","title":"1. Recursion Node (Formal Definition)","text":"<p>A recursion node ( R_t ) at step ( t ) is:</p> <p>[ R_t = \\left( C_t,\\; S_t,\\; K_t,\\; M_t \\right) ]</p> <p>Where: - ( C_t ) \u2014 content (task text or transformed instruction) - ( S_t ) \u2014 state slots (persistent intermediate memory) - ( K_t ) \u2014 active constraint set - ( M_t ) \u2014 metadata (optional semantic/structural hints)</p> <p>A single reasoning step is:</p> <p>[ O_t = f_{\\text{LM}}(R_t) ]</p>"},{"location":"math-core/#2-state-slot-dynamics","title":"2. State Slot Dynamics","text":"<p>A slot ( s_i ) is updated by:</p> <p>[ s_i^{(t+1)} = \\begin{cases} s_i^{(t)}, &amp; \\text{if locked} \\ g_i(O_t), &amp; \\text{otherwise} \\end{cases} ]</p> <p>Slots allow the model to: - accumulate intermediate results - divide tasks into components - maintain counters - preserve facts across steps  </p> <p>This is the \u201cworking memory\u201d that small LMs normally lack.</p>"},{"location":"math-core/#3-constraint-system","title":"3. Constraint System","text":"<p>Constraints act as mathematical guards on each step.</p> <p>Typical constraint types:</p>"},{"location":"math-core/#structural","title":"Structural","text":"<p>[ \\text{output must be JSON} ]</p>"},{"location":"math-core/#semantic","title":"Semantic","text":"<p>[ \\text{must include an explicit reasoning trace} ]</p>"},{"location":"math-core/#logical","title":"Logical","text":"<p>[ \\text{monotonic reasoning: do not contradict past steps} ]</p>"},{"location":"math-core/#depth","title":"Depth","text":"<p>[ t \\le t_{\\max} ]</p> <p>Constraints are evaluated as:</p> <p>[ K_t(O_t) = \\text{True or False} ]</p> <p>If a constraint fails:</p> <ul> <li>the step is rejected  </li> <li>the node is reissued with context + correction hint  </li> <li>the system stays stable  </li> </ul> <p>This is how MRS prevents drift.</p>"},{"location":"math-core/#4-drift-metric","title":"4. Drift Metric","text":"<p>Define drift ( D_t ) as:</p> <p>[ D_t = d(O_t,\\; C_t) ]</p> <p>Where ( d ) is a similarity or structural-distance function.</p> <p>If:</p> <p>[ D_t &gt; \\tau ]</p> <p>\u2192 MRS triggers a constraint correction step.</p> <p>This is the self-stabilizing property that prevents the model from \u201cwandering.\u201d</p>"},{"location":"math-core/#5-flow-controller-transition-function","title":"5. Flow Controller (Transition Function)","text":"<p>The transition function:</p> <p>[ R_{t+1} = T(R_t,\\; O_t) ]</p> <p>Where ( T ) performs:</p> <ol> <li>Slot updates  </li> <li>Constraint evaluation  </li> <li>Branching decisions  </li> <li>Halting detection  </li> </ol> <p>Branching example:</p> <p>[ T = {R_{t+1}^{(1)},\\; R_{t+1}^{(2)},\\ldots} ]</p> <p>Halting condition:</p> <p>[ H(R_t) = \\text{True when task is solved} ]</p>"},{"location":"math-core/#6-full-reasoning-chain","title":"6. Full Reasoning Chain","text":"<p>With everything together:</p> <p>[ {R_0,\\; R_1,\\; \\ldots,\\; R_T} ]</p> <p>Forms a transparent reasoning chain that can be inspected at any point.</p> <p>MRS guarantees:</p> <ul> <li>bounded drift  </li> <li>structural consistency  </li> <li>traceability  </li> <li>deterministic halting behavior (given constraints)  </li> </ul>"},{"location":"math-core/#summary","title":"Summary","text":"<p>The Math Core is what turns MRS into more than a prompt trick. It gives a small model:</p> <ul> <li>memory  </li> <li>structure  </li> <li>flow control  </li> <li>guardrails  </li> <li>the ability to reason across multiple steps  </li> </ul> <p>All while remaining simple, finite, and fast.</p>"},{"location":"operators/","title":"Operators","text":"<p>MRS defines a small, finite set of operators that control the flow of reasoning. Each operator transforms the current recursion node ( R_t ) in a predictable, interpretable way.</p> <p>Think of them as the instruction set of the MRS reasoning engine.</p>"},{"location":"operators/#1-infer","title":"1. <code>INFER</code>","text":"<p>Produces the next logical step in the reasoning chain.</p> <p>Purpose: Generate new content from the current context and state.</p> <p>Formal form:</p> <p>[ O_t = \\text{INFER}(R_t) ]</p> <p>Examples: - step-by-step deduction - combining slot values - deriving a new intermediate result  </p>"},{"location":"operators/#2-updateslot-value","title":"2. <code>UPDATE(slot, value)</code>","text":"<p>Writes a new value into a state slot.</p> <p>Purpose: Maintain persistent intermediate memory.</p> <p>Formal form:</p> <p>[ s_{\\text{slot}}^{(t+1)} = value ]</p> <p>Examples: - storing a partial computation - keeping a counter - saving extracted entities  </p>"},{"location":"operators/#3-branchoptions","title":"3. <code>BRANCH(options\u2026)</code>","text":"<p>Creates multiple child recursion paths.</p> <p>Purpose: Explore alternative solutions, interpretations, or strategies.</p> <p>Formal:</p> <p>[ {R_{t+1}^{(1)}, R_{t+1}^{(2)}, \\ldots } ]</p> <p>Examples: - exploring multiple summaries - trying alternate decompositions - generating alternate proofs  </p>"},{"location":"operators/#4-selectcondition","title":"4. <code>SELECT(condition)</code>","text":"<p>Chooses the best branch based on constraints or fit.</p> <p>Purpose: Prune the tree and stabilize the chain.</p> <p>[ R_{t+1} = \\operatorname*{argmin}_{i}\\; D(R_i) ]</p> <p>Where ( D ) is a drift or error metric.</p>"},{"location":"operators/#5-checkconstraint","title":"5. <code>CHECK(constraint)</code>","text":"<p>Evaluate whether the output matches a constraint.</p> <p>Purpose: Keep the reasoning chain aligned with rules.</p> <p>Formal:</p> <p>[ CHECK(K_t, O_t) \\rightarrow {pass, fail} ]</p> <p>Examples: - structure must be JSON - no contradictions allowed - step must follow chain-of-thought structure  </p> <p>If fail: \u2192 trigger repair loop.</p>"},{"location":"operators/#6-repair","title":"6. <code>REPAIR</code>","text":"<p>When a step violates constraints, <code>REPAIR</code> regenerates or corrects output.</p> <p>Purpose: Self-stabilization.</p> <p>Behavior: - regenerate the step - re-check constraints - preserve state slots  </p> <p>This prevents drift across long chains.</p>"},{"location":"operators/#7-halt","title":"7. <code>HALT</code>","text":"<p>Stops the reasoning chain.</p> <p>Purpose: Signal final output is complete.</p> <p>Formal:</p> <p>[ H(R_t) = \\text{True} ]</p> <p>Examples: - final answer reached - all constraints satisfied - no further steps needed  </p>"},{"location":"operators/#8-emitoutput","title":"8. <code>EMIT(output)</code>","text":"<p>Return the final formatted output to the user.</p> <p>Purpose: Provide the end result of the reasoning chain.</p>"},{"location":"operators/#operator-summary-table","title":"Operator Summary Table","text":"Operator Purpose INFER Generate next reasoning step UPDATE Write/update intermediate memory BRANCH Fork reasoning into parallel paths SELECT Choose best branch CHECK Validate constraints REPAIR Fix violations / drift HALT Stop computation EMIT Return final answer"},{"location":"operators/#notes","title":"Notes","text":"<ul> <li>Operators are intentionally minimal.  </li> <li>They form a complete set for multi-step reasoning.  </li> <li>This is not a programming language \u2014 it is a flow control system for LMs.  </li> <li>The simplicity keeps it robust and generalizable.</li> </ul>"},{"location":"overview/","title":"Overview","text":"<p>The Modular Reasoning Scaffold (MRS) is a lightweight, extensible framework for building stable, multi-step reasoning systems in Python. It provides a controlled execution environment for recursion, state management, functional operators, and node-based reasoning flows.</p>"},{"location":"overview/#1-architecture","title":"1. Architecture","text":"<p>MRS consists of five core components:</p>"},{"location":"overview/#1-state","title":"1. State","text":"<p>A persistent key/value store that survives across recursion steps and node executions.</p> <pre><code>from mrs.state import State\n\ns = State()\ns.update(\"x\", 5)\nprint(s.get(\"x\"))   # -&gt; 5\n</code></pre>"},{"location":"overview/#2-operators","title":"2. Operators","text":"<p>Pure functions that transform or evaluate values.</p> <pre><code>from mrs.operators import add, sub\n\nprint(add(3, 4))   # -&gt; 7\nprint(sub(10, 2))  # -&gt; 8\n</code></pre> <p>Custom operators can be defined easily:</p> <pre><code>def double(x):\n    return x * 2\n</code></pre>"},{"location":"overview/#3-nodes","title":"3. Nodes","text":"<p>Nodes wrap a reasoning step. Each node receives: - the global State - the input to that step</p> <pre><code>from mrs.nodes import Node\n\ndef step_fn(state, x):\n    state.update(\"latest\", x)\n    return x * 2\n\nn = Node(\"double_step\", step_fn)\n</code></pre>"},{"location":"overview/#4-chain","title":"4. Chain","text":"<p>Chains execute a sequence of nodes, passing State + outputs step to step.</p> <pre><code>from mrs.chain import Chain\nfrom mrs.nodes import Node\n\ndef a(state, x): return x + 1\ndef b(state, x): return x * 3\n\nchain = Chain([Node(\"a\", a), Node(\"b\", b)])\nresult = chain.run(5)   # ((5 + 1) * 3) = 18\n</code></pre>"},{"location":"overview/#5-mrs-high-level-interface","title":"5. MRS (High-level Interface)","text":"<p>Simple wrapper combining State + execution.</p> <pre><code>from mrs import MRS\n\nm = MRS()\nm.update(\"score\", 10)\nprint(m.get(\"score\"))   # -&gt; 10\n</code></pre>"},{"location":"overview/#summary","title":"Summary","text":"<p>MRS provides: - persistent state - functional operators - node-based reasoning - sequential chains - a simple high-level interface</p> <p>Together these form a controlled, stable recursive reasoning loop.</p>"}]}